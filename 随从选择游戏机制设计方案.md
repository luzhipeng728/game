# 随从选择游戏机制设计方案

## 📋 项目概述

基于你的需求，我们重新设计了整个多智能体系统，核心改变是将随从角色从自由对话模式改为**选择驱动模式**，创造更有策略性和紧张感的游戏体验。

## 🎯 核心设计理念

### 1. 游戏阶段控制
- **自由聊天阶段 (FREE_CHAT)**: 其他角色正常对话，随从等待
- **随从选择阶段 (FOLLOWER_CHOICE)**: 随从必须从选项中选择或输入自定义行动
- **游戏结束阶段 (GAME_ENDED)**: 计算最终得分和奖励

### 2. 限制性交互设计
- **随从角色**: 完全禁用自由输入，只能通过选择系统行动
- **其他角色**: 保持原有的自由对话模式
- **轮数限制**: 最多5轮随从行动，增加紧迫感

## 🏗️ 系统架构

### 智能体组成
```
🎮 游戏系统
├── 🤖 智能体协调器 (AgentCoordinator)
│   ├── 游戏阶段管理
│   ├── 数值状态跟踪
│   └── 轮数控制
├── 🎭 随从智能体 (FollowerAgent)
│   └── 生成3个行动选择
├── 📊 评分智能体 (EvaluatorAgent) 
│   └── 评估选择质量和影响
├── 🎬 旁白智能体 (NarratorAgent)
│   └── 生成故事反应
└── 其他角色智能体 (妓女、老鸨等)
    └── 正常对话模式
```

### 数据模型
```python
# 游戏阶段
class GamePhase(Enum):
    FREE_CHAT = "free_chat"
    FOLLOWER_CHOICE = "follower_choice" 
    GAME_ENDED = "game_ended"

# 随从选择
@dataclass
class FollowerChoice:
    choice_id: str
    content: str  # 行动描述
    risk_level: int  # 风险等级 1-5
    expected_values: Dict[str, int]  # 预期数值变化

# 游戏结果
class GameResult(Enum):
    SUCCESS = "success"
    FAILURE = "failure"
    NEUTRAL = "neutral"
```

## 🎲 游戏机制

### 选择生成系统
1. **触发条件**: 
   - 消息包含行动关键词
   - 紧张度达到阈值
   - 旁白主动触发

2. **选择生成**:
   - 随从智能体生成3个不同风险等级的选择
   - 每个选择包含风险评估和预期效果
   - 玩家可选择预设选项或输入自定义行动

### 评分系统
```python
# 评估维度
evaluation = {
    "scores": {
        "quality": 7,           # 行动质量 (1-10)
        "risk_assessment": 6,   # 风险评估
        "appropriateness": 8,   # 适当性
        "strategic_value": 7    # 战略价值
    },
    "value_changes": {
        "tension": 2,    # 紧张度变化
        "suspicion": 1,  # 怀疑度变化
        "charm": 3,      # 魅力值变化
        "skill": 2,      # 技巧值变化
        "composure": 0   # 镇定值变化
    },
    "explanation": "详细的评估解释"
}
```

### 数值系统
```python
# 当前数值
scene_values = {
    "tension": 0,      # 紧张度 (-50 ~ 100)
    "suspicion": 0,    # 怀疑度 (-50 ~ 100)
    "charm": 0,        # 魅力值 (-50 ~ 100)
    "skill": 0,        # 技巧值 (-50 ~ 100)
    "composure": 0     # 镇定值 (-50 ~ 100)
}

# 目标数值
target_values = {
    "tension": 30,      # 需要达到30
    "suspicion": -20,   # 需要降到-20以下
    "charm": 25,        # 需要达到25
    "skill": 20,        # 需要达到20
    "composure": 15     # 需要达到15
}
```

## 🎮 游戏流程

### 1. 游戏开始
```
用户连接 → 角色分配 → 初始化场景 → 自由聊天阶段
```

### 2. 选择触发
```
触发条件满足 → 生成选择选项 → 显示选择界面 → 等待玩家选择
```

### 3. 选择处理
```
玩家选择 → 智能评分 → 应用数值变化 → 旁白反应 → 检查结束条件
```

### 4. 游戏结束
```
条件满足 → 计算最终得分 → 显示结果 → 奖励/惩罚
```

## 💻 前端界面

### 正常输入模式
```html
<div id="normal-input">
    <input type="text" placeholder="输入消息...">
    <button>发送</button>
</div>
```

### 随从选择模式  
```html
<div id="follower-choice-mode">
    <div class="round-info">轮次: 2/5</div>
    <div class="follower-choices">
        <button class="choice-button risk-1">
            <div class="choice-title">安全选择</div>
            <div class="choice-content">小心观察环境...</div>
            <div class="choice-expected">预期: composure+3, tension-1</div>
        </button>
        <!-- 更多选择... -->
    </div>
    <div class="custom-input-section">
        <input type="text" placeholder="或输入自定义行动...">
        <button>发送</button>
    </div>
</div>
```

## 🏆 奖励系统

### 成功条件
- **目标达成**: 70%以上目标数值达到要求
- **轮数内完成**: 在5轮内达成目标

### 失败条件
- **被发现**: 怀疑度超过80
- **行为不当**: 过多粗口等负面行为

### 得分计算
```python
def calculate_final_score(reason, completion_rate, scene_values):
    base_score = 0
    
    if reason == "success":
        base_score = 100
    elif reason == "failure":
        base_score = 0
    elif reason == "time_limit":
        base_score = int(50 + completion_rate * 50)
    
    # 奖励修正
    value_bonus = sum(max(0, v) for v in scene_values.values()) // 10
    return max(0, base_score + value_bonus)
```

## 🔧 技术实现

### 消息类型扩展
```python
# 新增WebSocket消息类型
message_types = {
    'follower_choices',      # 发送选择选项
    'game_phase_change',     # 游戏阶段变化
    'evaluation_result',     # 评估结果
    'game_ended'            # 游戏结束
}
```

### 智能体协调流程
```python
async def coordinate_agent_responses(self, user_message, scene_state, username, user_role):
    # 1. 检查是否是随从选择
    if self.game_phase == GamePhase.FOLLOWER_CHOICE and user_role == 'human_follower':
        return await self._handle_follower_choice(user_message, scene_state, username)
    
    # 2. 检查是否需要触发选择
    if self._should_trigger_follower_choice(user_message, scene_state):
        return await self._trigger_follower_choice(scene_state, username)
    
    # 3. 正常智能体响应
    return await self._normal_agent_responses(user_message, scene_state)
```

## 📊 优化建议讨论点

### 1. 平衡性调整
- **风险回报比**: 高风险选择是否应该有更高回报？
- **数值范围**: 当前-50~100的范围是否合适？
- **目标难度**: 目标数值设置是否需要动态调整？

### 2. 体验优化
- **选择多样性**: 如何确保每轮选择都有新意？
- **反馈及时性**: 评估结果显示的时机和方式
- **紧张感营造**: 如何通过UI和文案增强紧迫感？

### 3. 智能体行为
- **选择生成质量**: 如何确保AI生成的选择有创意且平衡？
- **评分公平性**: 评分算法是否需要加入更多维度？
- **故事连贯性**: 旁白如何保持故事的连贯性？

### 4. 扩展功能
- **多人协作**: 是否支持多个随从协作？
- **技能系统**: 是否添加随从的特殊技能？
- **成就系统**: 是否添加解锁条件和成就？

## 🚀 部署和测试

### 测试文件
- `demo_follower_choice_system.py`: 核心机制演示
- `test_evaluation_system.py`: 评分系统测试
- `test_game_balance.py`: 游戏平衡性测试

### 部署步骤
1. 启动WebSocket服务器: `python start_websocket_server.py`
2. 访问客户端: `chat_client.html`
3. 选择角色: `human_follower`
4. 开始游戏测试

## 📝 总结

这个新的随从选择系统将原来的自由对话模式转变为策略选择模式，具有以下优势：

✅ **策略性增强**: 每个选择都有明确的风险和回报
✅ **紧张感提升**: 轮数限制和实时评分增加压力
✅ **平衡性保证**: 智能评分系统确保公平性
✅ **故事性保持**: 旁白智能体维持叙事连贯性
✅ **可扩展性**: 模块化设计便于后续功能扩展

这个设计为游戏提供了更丰富的策略深度，同时保持了AI驱动的故事叙事特色。 